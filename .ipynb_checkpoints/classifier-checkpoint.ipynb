{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data():\n",
    "    stoplist_file = open('data/stoplist.txt')\n",
    "    traindata_file = open('data/traindata.txt')\n",
    "    trainlabel_file = open('data/trainlabels.txt')\n",
    "    testdata_file = open('data/testdata.txt')\n",
    "    testlabel_file = open('data/testlabels.txt')\n",
    "    \n",
    "    stop_words = []\n",
    "    train_data = []\n",
    "    train_label = []\n",
    "    test_data = []\n",
    "    test_label = []\n",
    "    \n",
    "    for line in stoplist_file:\n",
    "        line = line.replace('\\n', '')\n",
    "        stop_words.append(line)\n",
    "        \n",
    "    for line in traindata_file:\n",
    "        line = line.replace('\\n', '')\n",
    "        train_data.append(line)\n",
    "        \n",
    "    for line in trainlabel_file:\n",
    "        line = line.replace('\\n', '')\n",
    "        if(line == '1'):\n",
    "            train_label.append('future')\n",
    "        else:\n",
    "            train_label.append('saying')\n",
    "    \n",
    "    for line in testdata_file:\n",
    "        line = line.replace('\\n', '')\n",
    "        test_data.append(line)\n",
    "    \n",
    "    for line in testlabel_file:\n",
    "        line = line.replace('\\n', '')\n",
    "        if(line == '1'):\n",
    "            test_label.append('future')\n",
    "        else:\n",
    "            test_label.append('saying')\n",
    "        \n",
    "    return (stop_words, train_data, train_label, test_data, test_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(stop_words, train_data):\n",
    "    \n",
    "    vocabulary = []\n",
    "    \n",
    "    for line in train_data:\n",
    "        line = line.replace('\\n', '')\n",
    "        line = line.split(' ')\n",
    "        for word in line:\n",
    "            if word not in stop_words and word not in vocabulary and len(word) > 0:\n",
    "                vocabulary.append(word)\n",
    "    vocabulary.sort()\n",
    "    return vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_feature(vocabulary, train_data, train_label, test_data, test_label):\n",
    "    \n",
    "    train_x = np.zeros((len(train_data), len(vocabulary)))\n",
    "    test_x = np.zeros((len(test_data), len(vocabulary)))\n",
    "    \n",
    "    train_count = 0\n",
    "    \n",
    "    for line in train_data:\n",
    "        line = line.replace('\\n', '')\n",
    "        line = line.split(' ')\n",
    "        for word in line:\n",
    "            if word in vocabulary:\n",
    "                index = vocabulary.index(word)\n",
    "                train_x[train_count][index] = 1\n",
    "                \n",
    "        train_count += 1\n",
    "        \n",
    "    test_count = 0\n",
    "    \n",
    "    for line in test_data:\n",
    "        line = line.replace('\\n', '')\n",
    "        line = line.split(' ')\n",
    "        for word in line:\n",
    "            if word in vocabulary:\n",
    "                index = vocabulary.index(word)\n",
    "                test_x[test_count][index] = 1\n",
    "                \n",
    "        test_count += 1\n",
    "    \n",
    "    train_x = pd.DataFrame(train_x, columns = vocabulary)\n",
    "    test_x = pd.DataFrame(test_x, columns = vocabulary)\n",
    "    \n",
    "    train_y = pd.DataFrame(train_label, columns = ['label'])\n",
    "    test_y =  pd.DataFrame(test_label, columns = ['label'])\n",
    "    \n",
    "    return (train_x, train_y, test_x, test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NaiveBayes():\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.attribute_estimates = {}\n",
    "        self.class_estimates = {}\n",
    "        \n",
    "    def fit(self, x, y):\n",
    "        \n",
    "        attributes = x.columns.values\n",
    "        labels = y.columns.values\n",
    "        \n",
    "        for label in labels:\n",
    "            value, count = np.unique(y[label], return_counts = True)\n",
    "            value_count = dict(zip(value, count))\n",
    "            for key, value in value_count.items():\n",
    "                self.class_estimates[key] = value_count[key] / y.shape[0]\n",
    "        \n",
    "        word_dict = {}\n",
    "        \n",
    "        for attribute in attributes:\n",
    "            value, count = np.unique(x[attribute], return_counts = True)\n",
    "            value_count = dict(zip(value, count))\n",
    "            word_dict[attribute] = value_count\n",
    "            \n",
    "            for v in value:\n",
    "                y_l = y.values\n",
    "                index = np.where(x[attribute] == v)\n",
    "                corr_y = np.take(y_l, index)[0]\n",
    "                ops, total = np.unique(corr_y, return_counts = True)\n",
    "                ops_total = dict(zip(ops, total))\n",
    "                total = np.sum(list(ops_total.values()))\n",
    "                \n",
    "                for key, val in ops_total.items():\n",
    "                    ops_total[key] = ops_total[key] / total\n",
    "                print(v, total, ops_total)\n",
    "            \n",
    "                \n",
    "    def score(self, x, y):\n",
    "        pass\n",
    "    \n",
    "    def predict(self):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    # Read the data from text file\n",
    "    (stop_words, train_data, train_label, test_data, test_label) = read_data()\n",
    "    \n",
    "    # Create a vocabulary of words \n",
    "    vocabulary = preprocess(stop_words, train_data)\n",
    "    \n",
    "    # Convert the data into feature vector\n",
    "    (train_x, train_y, test_x, test_y) = convert_to_feature(vocabulary, train_data, train_label, test_data, test_label)\n",
    "    \n",
    "    # Instantiate Naive Bayes classifier object\n",
    "    nb = NaiveBayes()\n",
    "    \n",
    "    # Fit model on training data\n",
    "    nb.fit(train_x, train_y)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0 318 {'future': 151, 'saying': 167}\n",
      "0.0 318 {'future': 0.4748427672955975, 'saying': 0.5251572327044025}\n",
      "1.0 4 {'future': 1, 'saying': 3}\n",
      "1.0 4 {'future': 0.25, 'saying': 0.75}\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
