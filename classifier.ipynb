{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.naive_bayes import MultinomialNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data():\n",
    "    stoplist_file = open('data/stoplist.txt')\n",
    "    traindata_file = open('data/traindata.txt')\n",
    "    trainlabel_file = open('data/trainlabels.txt')\n",
    "    testdata_file = open('data/testdata.txt')\n",
    "    testlabel_file = open('data/testlabels.txt')\n",
    "    \n",
    "    stop_words = []\n",
    "    train_data = []\n",
    "    train_label = []\n",
    "    test_data = []\n",
    "    test_label = []\n",
    "    \n",
    "    for line in stoplist_file:\n",
    "        line = line.replace('\\n', '')\n",
    "        stop_words.append(line)\n",
    "        \n",
    "    for line in traindata_file:\n",
    "        line = line.replace('\\n', '')\n",
    "        train_data.append(line)\n",
    "        \n",
    "    for line in trainlabel_file:\n",
    "        line = line.replace('\\n', '')\n",
    "        train_label.append(int(line))\n",
    "    \n",
    "    for line in testdata_file:\n",
    "        line = line.replace('\\n', '')\n",
    "        test_data.append(line)\n",
    "    \n",
    "    for line in testlabel_file:\n",
    "        line = line.replace('\\n', '')\n",
    "        test_label.append(int(line))\n",
    "        \n",
    "    return (stop_words, train_data, train_label, test_data, test_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(stop_words, train_data):\n",
    "    \n",
    "    vocabulary = []\n",
    "    \n",
    "    for line in train_data:\n",
    "        line = line.replace('\\n', '')\n",
    "        line = line.split(' ')\n",
    "        for word in line:\n",
    "            if word not in stop_words and word not in vocabulary and len(word) > 0:\n",
    "                vocabulary.append(word)\n",
    "    vocabulary.sort()\n",
    "    return vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_feature(vocabulary, train_data, train_label, test_data, test_label):\n",
    "    \n",
    "    train_x = np.zeros((len(train_data), len(vocabulary)))\n",
    "    test_x = np.zeros((len(test_data), len(vocabulary)))\n",
    "    \n",
    "    train_count = 0\n",
    "    \n",
    "    for line in train_data:\n",
    "        line = line.replace('\\n', '')\n",
    "        line = line.split(' ')\n",
    "        for word in line:\n",
    "            if word in vocabulary:\n",
    "                index = vocabulary.index(word)\n",
    "                train_x[train_count][index] = 1\n",
    "                \n",
    "        train_count += 1\n",
    "        \n",
    "    test_count = 0\n",
    "    \n",
    "    for line in test_data:\n",
    "        line = line.replace('\\n', '')\n",
    "        line = line.split(' ')\n",
    "        for word in line:\n",
    "            if word in vocabulary:\n",
    "                index = vocabulary.index(word)\n",
    "                test_x[test_count][index] = 1\n",
    "                \n",
    "        test_count += 1\n",
    "    \n",
    "    train_y = list(map(int, train_label))\n",
    "    test_y = list(map(int, test_label))\n",
    "    \n",
    "    train_x = pd.DataFrame(train_x, columns = vocabulary)\n",
    "    test_x = pd.DataFrame(test_x, columns = vocabulary)\n",
    "    \n",
    "    train_y = pd.DataFrame(train_y, columns = ['label'])\n",
    "    test_y =  pd.DataFrame(test_y, columns = ['label'])\n",
    "    \n",
    "    return (train_x, train_y, test_x, test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_output(train_accuracy, test_accuracy, train_accuracy_sk, test_accuracy_sk):\n",
    "    \n",
    "    file = open('naive_bayes.txt', 'w+')\n",
    "    \n",
    "    file.write('##### Naive Bayes Implementation Output #####\\n\\n')\n",
    "    file.write('Train accuracy: ' + str(train_accuracy) + ' %\\n')\n",
    "    file.write('Test accuracy: ' + str(test_accuracy) + ' %\\n')\n",
    "    file.write('\\n\\n##### Naive Bayes SKLearn Output #####\\n\\n')\n",
    "    file.write('Train accuracy: ' + str(train_accuracy_sk) + ' %\\n')\n",
    "    file.write('Test accuracy: ' + str(test_accuracy_sk) + ' %\\n')\n",
    "    file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NaiveBayes():\n",
    "    \n",
    "    def __init__(self, vocabulary):\n",
    "        self.attribute_estimates = {}\n",
    "        self.class_estimates = {}\n",
    "        self.vocabulary = vocabulary\n",
    "        \n",
    "    def fit(self, x, y):\n",
    "        c = 0\n",
    "        attributes = x.columns.values\n",
    "        labels = y.columns.values\n",
    "        \n",
    "        for label in labels:\n",
    "            value, count = np.unique(y[label], return_counts = True)\n",
    "            value_count = dict(zip(value, count))\n",
    "            for key, value in value_count.items():\n",
    "                self.class_estimates[key] = value_count[key] / y.shape[0]\n",
    "         \n",
    "        for attribute in attributes:\n",
    "            value, count = np.unique(x[attribute], return_counts = True)\n",
    "            \n",
    "            word_dict = {}\n",
    "            \n",
    "            for v in value:\n",
    "                y_l = y.values\n",
    "                index = np.where(x[attribute] == v)\n",
    "                corr_y = np.take(y_l, index)[0]\n",
    "                ops, total = np.unique(corr_y, return_counts = True)\n",
    "                ops_total = dict(zip(ops, total))\n",
    "                total = np.sum(list(ops_total.values()))\n",
    "                \n",
    "                for key, val in ops_total.items():\n",
    "                    ops_total[key] = (ops_total[key] + 1) / (total + 2)\n",
    "                \n",
    "                # Handle values which doesn't appear in dictionary\n",
    "                if(len(ops_total) == 1):\n",
    "                    key = list(ops_total.keys())\n",
    "                    if(key[0] == 0):\n",
    "                        ops_total[1] = 1 - ops_total[key[0]]\n",
    "                    else:\n",
    "                        ops_total[0] = 1 - ops_total[key[0]]\n",
    "                \n",
    "                word_dict[v] = ops_total\n",
    "                \n",
    "            self.attribute_estimates[attribute] = word_dict\n",
    "            \n",
    "           \n",
    "    def score(self, x, y):\n",
    "        pred_future = 1\n",
    "        pred_saying = 1\n",
    "        y_hat = []\n",
    "        for i in range(len(x)):\n",
    "            j = 0\n",
    "            attributes = x[i].split(' ')\n",
    "            for attribute in attributes:\n",
    "                if attribute not in self.vocabulary:\n",
    "                    continue\n",
    "                else:\n",
    "                    pred_future *= self.attribute_estimates[attribute][1.0][1]\n",
    "                    pred_saying *= self.attribute_estimates[attribute][1.0][0]\n",
    "                    j += 1\n",
    "            pred_future *= self.class_estimates[1]\n",
    "            pred_saying *= self.class_estimates[0]\n",
    "            if(pred_future > pred_saying):\n",
    "                y_hat.append(1)\n",
    "            else:\n",
    "                y_hat.append(0)\n",
    "            pred_future = 1\n",
    "            pred_saying = 1\n",
    "        accuracy = self.calculate_accuracy(y_hat, y)\n",
    "        return accuracy\n",
    "        \n",
    "    def calculate_accuracy(self, y_hat, y):\n",
    "        y_hat = np.asarray(y_hat)\n",
    "        y = np.asarray(y)\n",
    "        \n",
    "        count = np.equal(y_hat, y)\n",
    "        value, count = np.unique(count, return_counts = True)\n",
    "        val_count = dict(zip(value, count))\n",
    "        \n",
    "        accuracy = 1 - (val_count[False] / y_hat.shape[0])\n",
    "        \n",
    "        return accuracy\n",
    "        \n",
    "    def predict(self):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    # Read the data from text file\n",
    "    (stop_words, train_data, train_label, test_data, test_label) = read_data()\n",
    "    \n",
    "    # Create a vocabulary of words \n",
    "    vocabulary = preprocess(stop_words, train_data)\n",
    "    \n",
    "    # Convert the data into feature vector\n",
    "    (train_x, train_y, test_x, test_y) = convert_to_feature(vocabulary, train_data, train_label, test_data, test_label)\n",
    "    \n",
    "    # Instantiate Naive Bayes classifier object\n",
    "    nb = NaiveBayes(vocabulary)\n",
    "    \n",
    "    # Fit model on training data\n",
    "    nb.fit(train_x, train_y)\n",
    "    \n",
    "    # Accuracy for train data\n",
    "    train_accuracy = nb.score(train_data, train_label) * 100\n",
    "    \n",
    "    # Accuracy for test data\n",
    "    test_accuracy = nb.score(test_data, test_label) * 100\n",
    "    \n",
    "    # Use SKlearn to verify\n",
    "    clf = MultinomialNB()\n",
    "    \n",
    "    # Fit train data to our model\n",
    "    clf.fit(train_x, train_y)\n",
    "    \n",
    "    # SKlearn accuracy for train data\n",
    "    train_accuracy_sk = clf.score(train_x, train_y) * 100\n",
    "    \n",
    "    # SKlearn accuracy for test data\n",
    "    test_accuracy_sk = clf.score(test_x, test_y) * 100\n",
    "    \n",
    "    # Write output to file\n",
    "    create_output(train_accuracy, test_accuracy, train_accuracy_sk, test_accuracy_sk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\lib\\site-packages\\sklearn\\utils\\validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
